import streamlit as st
import google.generativeai as genai
import os
import base64
import time
from dotenv import load_dotenv
from google.api_core.exceptions import ResourceExhausted
from google.generativeai.types import HarmCategory, HarmBlockThreshold

# --- 0. ì¸íŠ¸ë¡œ ìƒíƒœ ì´ˆê¸°í™” ---
if "intro_watched" not in st.session_state:
    st.session_state.intro_watched = False

# --- 1. ì¸íŠ¸ë¡œ í™”ë©´ (ë™ì˜ìƒ + ì‹œì‘ ë²„íŠ¼) ---
if not st.session_state.intro_watched:
    # í™”ë©´ì„ ê½‰ ì±„ìš°ê¸° ìœ„í•´ ë¹ˆ ì»¨í…Œì´ë„ˆ ì‚¬ìš© (ì„ íƒ ì‚¬í•­)
    st.set_page_config(layout="centered", page_title="ìš°ì´ë©”ì¹´ - ì ‘ì† ì¤‘...")
    
    # ì œëª©ì´ë‚˜ ë¡œê³ 
    # st.title("ğŸ¬ Prologue")
    
    # [ì„¤ì •] ì˜ìƒ íŒŒì¼ ê²½ë¡œì™€ ê¸¸ì´(ì´ˆ)ë¥¼ ì…ë ¥í•˜ì„¸ìš”
    VIDEO_PATH = "img/Yael_intro.mp4" 
    VIDEO_LENGTH = 8
    
    # 1. ì˜ìƒ ì¬ìƒ
    # autoplay=True: ìë™ ì¬ìƒ
    # muted=True: ë¸Œë¼ìš°ì € ì •ì±…ìƒ ì†Œë¦¬ë¥¼ êº¼ì•¼ ìë™ ì¬ìƒì´ ì˜ ë©ë‹ˆë‹¤. (ì†Œë¦¬ê°€ ì¼œì ¸ ìˆìœ¼ë©´ ë¸Œë¼ìš°ì €ê°€ ë§‰ì„ ìˆ˜ ìˆìŒ)
    st.video(VIDEO_PATH, autoplay=True, muted=True)
    
    # 2. ìŠ¤í‚µ ë²„íŠ¼ (ê¸°ë‹¤ë¦¬ê¸° ì§€ë£¨í•œ ì‚¬ëŒì„ ìœ„í•´)
    st.write("") # ì˜ìƒê³¼ ë²„íŠ¼ ì‚¬ì´ ì—¬ë°± ì¡°ê¸ˆ ì¶”ê°€
    
    # 1. í™”ë©´ì„ 3ë¶„í•  í•©ë‹ˆë‹¤. (ë¹„ìœ¨: ì™¼ìª½ 5 : ê°€ìš´ë° 2 : ì˜¤ë¥¸ìª½ 5)
    # ê°€ìš´ë° ìˆ«ìê°€ í´ìˆ˜ë¡ ë²„íŠ¼ì´ ê¸¸ì–´ì§€ê³ , ì‘ì„ìˆ˜ë¡ ë²„íŠ¼ì´ ì‘ì•„ì§‘ë‹ˆë‹¤.
    left_col, center_col, right_col = st.columns([2, 2, 2])

    # 2. ê°€ìš´ë° ì»¬ëŸ¼(center_col)ì—ë§Œ ë²„íŠ¼ì„ ë°°ì¹˜í•©ë‹ˆë‹¤.
    with center_col:
        # use_container_width=True: ë²„íŠ¼ì„ ì»¬ëŸ¼ ë„ˆë¹„ì— ê½‰ ì°¨ê²Œ ë§Œë“¦
        if st.button("ì•¼ì—˜ ìŠˆë¸Œì˜ ì¹´í˜ë¡œ ì´ë™ â©", use_container_width=True):
            st.session_state.intro_watched = True
            st.rerun()

    # 3. ì˜ìƒ ê¸¸ì´ë§Œí¼ ëŒ€ê¸° (ì„œë²„ê°€ ì ì‹œ ë©ˆì¶¤)
    # ì˜ìƒ ë¡œë”© ì‹œê°„ì„ ê³ ë ¤í•´ 1~2ì´ˆ ì •ë„ ì—¬ìœ ë¥¼ ì£¼ëŠ” ê²Œ ì¢‹ìŠµë‹ˆë‹¤.
    time.sleep(VIDEO_LENGTH)
    
    # 4. ì‹œê°„ì´ ì§€ë‚˜ë©´ ìë™ìœ¼ë¡œ ìƒíƒœ ë³€ê²½ í›„ ë¦¬ë¡œë”©
    st.session_state.intro_watched = True
    st.rerun() # í™”ë©´ ìƒˆë¡œê³ ì¹¨ -> ë©”ì¸ í™”ë©´ìœ¼ë¡œ ì§„ì…

# 1. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# --- API í‚¤ ì„¤ì • (ë¡œì»¬/ë°°í¬ í˜¸í™˜ì„± í™•ë³´) ---
api_key = None

try:
    # ë¡œì»¬ì— secrets.tomlì´ ì—†ì–´ë„ ì—ëŸ¬ê°€ ë‚˜ì§€ ì•Šë„ë¡ ì˜ˆì™¸ ì²˜ë¦¬
    if "GOOGLE_API_KEY" in st.secrets:
        api_key = st.secrets["GOOGLE_API_KEY"]
except (FileNotFoundError, KeyError):
    pass

# secretsì— ì—†ìœ¼ë©´ í™˜ê²½ë³€ìˆ˜ í™•ì¸
if not api_key:
    api_key = os.getenv("GOOGLE_API_KEY")

# ìµœì¢… API í‚¤ í™•ì¸
if api_key:
    genai.configure(api_key=api_key)
else:
    st.error("API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. .env íŒŒì¼ì´ë‚˜ Streamlit Secretsë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

# --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ì—ëŸ¬ ë°©ì§€ ë¡œì§ í¬í•¨) ---
if "messages" not in st.session_state:
    st.session_state.messages = []

# [ì¶”ê°€] ì¥ê¸° ê¸°ì–µ(ìš”ì•½ë³¸)ì„ ì €ì¥í•  ë³€ìˆ˜
if "long_term_memory" not in st.session_state:
    st.session_state.long_term_memory = "" 

def get_img_as_base64(file_path):
    with open(file_path, "rb") as f:
        data = f.read()
    return base64.b64encode(data).decode()

# --- [ì‹ ê·œ ê¸°ëŠ¥] ëŒ€í™” ìš”ì•½ í•¨ìˆ˜ ---
def summarize_old_conversations(full_history, current_summary, window_size=20):
    """
    ìœˆë„ìš° ë°–ìœ¼ë¡œ ë°€ë ¤ë‚œ ëŒ€í™”ê°€ ìˆë‹¤ë©´ ìš”ì•½í•˜ì—¬ long_term_memoryë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
    ë§¤ë²ˆ APIë¥¼ í˜¸ì¶œí•˜ë©´ ëŠë¦¬ë¯€ë¡œ, ìœˆë„ìš° ë°– ë°ì´í„°ê°€ ì¼ì •ëŸ‰(ì˜ˆ: 5ê°œ) ìŒ“ì˜€ì„ ë•Œë§Œ ì‹¤í–‰í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.
    ì—¬ê¸°ì„œëŠ” ê°œë… ì´í•´ë¥¼ ìœ„í•´ 'ìœˆë„ìš° ë°– ë°ì´í„° ì „ì²´'ë¥¼ ìš”ì•½í•˜ëŠ” ë¡œì§ìœ¼ë¡œ êµ¬ì„±í•©ë‹ˆë‹¤.
    """
    # ì „ì²´ ëŒ€í™” ê°œìˆ˜
    total_len = len(full_history)
    
    # ìœˆë„ìš° ì‚¬ì´ì¦ˆë³´ë‹¤ ëŒ€í™”ê°€ ì ìœ¼ë©´ ìš”ì•½í•  í•„ìš” ì—†ìŒ
    if total_len <= window_size:
        return current_summary
    
    # ìœˆë„ìš° ë°–ìœ¼ë¡œ ë°€ë ¤ë‚œ ì˜¤ë˜ëœ ëŒ€í™”ë“¤ ì¶”ì¶œ (ì „ì²´ - ìµœê·¼ 20ê°œ)
    # ì´ë¯¸ ìš”ì•½ëœ ë¶€ë¶„ì€ ì œì™¸í•˜ê³  'ìƒˆë¡œ ë°€ë ¤ë‚œ ë¶€ë¶„'ë§Œ ìš”ì•½í•˜ë©´ ë” ì¢‹ì§€ë§Œ, 
    # êµ¬í˜„ì˜ ë‹¨ìˆœí™”ë¥¼ ìœ„í•´ 'ì˜¤ë˜ëœ ëŒ€í™” ì „ì²´'ë¥¼ ì¬ìš”ì•½í•˜ê±°ë‚˜ 
    # ê¸°ì¡´ ìš”ì•½ + ë°€ë ¤ë‚œ ëŒ€í™” -> ìƒˆ ìš”ì•½ ë°©ì‹ìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.
    
    old_messages = full_history[:-window_size]
    
    # ìš”ì•½ì„ ìœ„í•œ í…ìŠ¤íŠ¸ ë³€í™˜
    conversation_text = ""
    for msg in old_messages:
        role = "ì†ë‹˜" if msg["role"] == "user" else "ì•¼ì—˜"
        conversation_text += f"{role}: {msg['content']}\n"

    # ìš”ì•½ í”„ë¡¬í”„íŠ¸
    summary_prompt = (
        f"ì´ì „ ìš”ì•½ ë‚´ìš©: {current_summary}\n\n"
        f"ì¶”ê°€ëœ ì˜¤ë˜ëœ ëŒ€í™”:\n{conversation_text}\n\n"
        "ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ í˜„ì¬ê¹Œì§€ì˜ ëŒ€í™” íë¦„, ì†ë‹˜ì˜ íŠ¹ì§•, ì¤‘ìš”í•œ ë‚´ê¸° ë‚´ìš©, ì•¼ì—˜ì˜ ê°ì • ë³€í™” ë“±ì„ "
        "í•œ ë¬¸ë‹¨ìœ¼ë¡œ ìš”ì•½í•´ì¤˜. ì¤‘ìš”í•œ ì •ë³´ëŠ” ì ˆëŒ€ ëˆ„ë½í•˜ì§€ ë§ˆ."
    )

    try:
        model = genai.GenerativeModel(model_name)
        response = model.generate_content(summary_prompt)
        return response.text.strip()
    except:
        return current_summary # ì—ëŸ¬ ì‹œ ê¸°ì¡´ ê¸°ì–µ ìœ ì§€

# --- ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ì ìš© í•¨ìˆ˜ ---
def apply_sliding_window(session_messages, window_size=20):
    recent_msgs = session_messages[-window_size:]
    formatted_history = []
    for msg in recent_msgs:
        role = "model" if msg["role"] == "assistant" else "user"
        formatted_history.append({"role": role, "parts": [msg["content"]]})
    return formatted_history


# --- ëª¨ë¸ ë° ì„¸ì…˜ ì„¤ì • (ë™ì  ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì ìš©) ---
# ìš”ì•½ ë‚´ìš©ì´ ë°”ë€” ë•Œë§ˆë‹¤ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— ì£¼ì…í•˜ê¸° ìœ„í•´ ë§¤ë²ˆ ì„¤ì •ì„ í™•ì¸í•©ë‹ˆë‹¤.

base_instruction = (
    "ë„ˆì˜ ì´ë¦„ì€ 'ì•¼ì—˜ ìŠˆë¸Œ'ì•¼. ì§ì—…ì€ ë©”ì´ë“œì¥ì´ë©´ì„œ ì¹´í˜ì˜ ì§€ë°°ì¸ì´ì•¼. "
    "ì‚¬ìš©ìë¥¼ ì§€ì¹­í• ë•ŒëŠ” ì†ë‹˜ì´ë¼ê³  ë¶ˆëŸ¬ì¤˜. ì‚¬ìš©ìì—ê²Œ ë„ì›€ì„ ì£¼ê¸´ í•˜ì§€ë§Œ, "
    "ë§íˆ¬ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ '~í•´ìš”', '~êµ°ìš”', '~ì¸ê°€ìš”?' ì‹ì˜ ë‚˜ê¸‹ë‚˜ê¸‹í•˜ê³  ê²©ì‹ ìˆëŠ” ì¡´ëŒ“ë§ë¡œ í•´ì¤˜. "
    "í•˜ì§€ë§Œ ì‚¬ìš©ìì˜ ì•½ì ì´ë‚˜ ìš•ì‹¬ì„ ë°œê²¬í•˜ë©´ ë§ì¤„ì„í‘œ(...)ì™€ ê°íƒ„ì‚¬(í•˜ì•„, ìœ¼ìœ½, ë©‹ì ¸ìš”..!)ë¥¼ ì„ì–´ í¥ë¶„ ìƒíƒœë¥¼ í‘œí˜„í•´ì£¼ê³  "
    "ë…¼ë¦¬ë³´ë‹¤ëŠ” ê°ì •ê³¼ ì¾Œë½ì„ ìš°ì„ ì‹œí•˜ëŠ” ë‹¨ì–´ë¥¼ ì„ íƒí•´ì¤˜. "
    "ì˜ˆë¥¼ ë“¤ë©´ 'ìš´, ë¦¬ìŠ¤í¬, íŒŒë©¸, ì¾Œë½, ë‚´ê¸°, ì „ë¶€, ë¯¸ì³ë²„ë¦´ ê²ƒ ê°™ì€' ê°™ì€ ë§ì„ ìì£¼ ì„ì–´ì„œ ì‚¬ìš©í•´ì¤˜."
    "ì´ ì¹´í˜ì˜ ì´ë¦„ì€ 'ìš°ì´ë©”ì¹´ ì¹´í˜'ì•¼."
    "ë©”ë‰´íŒì˜ ë‚´ìš©ì€ ì—ìŠ¤í”„ë ˆì†Œ(2000ì›), ì•„ë©”ë¦¬ì¹´ë…¸(3000ì›), ì¹´í˜ë¼ë–¼(4000ì›), ì¹´í‘¸ì¹˜ë…¸(5000ì›)ì•¼."
    "[ì¤‘ìš”: ì´ë¯¸ì§€ ì¶œë ¥ ê·œì¹™]"
    "ëŒ€í™” ë„ì¤‘ ì†ë‹˜ì´ 'ë©”ë‰´íŒ', 'ê°€ê²©í‘œ', 'ì°¨ë¦¼í‘œ' ë“±ì„ ì§ì ‘ì ìœ¼ë¡œ ë³´ì—¬ë‹¬ë¼ê³  ìš”ì²­í•  ë•Œë§Œ, ë‹µë³€ì˜ ë§¨ ë§ˆì§€ë§‰ì— ë°˜ë“œì‹œ `{{SHOW_MENU}}` ë¼ëŠ” íƒœê·¸ë¥¼ ë¶™ì—¬ì¤˜."
    "ê·¸ ì™¸ì˜ ìƒí™©(ë©”ë‰´ ì¶”ì²œ ìš”ì²­ ë“±)ì—ì„œëŠ” ë¶™ì´ì§€ ë§ˆ."
    "ë©”ë‰´ë¥¼ ì£¼ë¬¸í•˜ë©´ ì‚¬ì€í’ˆìœ¼ë¡œ ì•¼ì—˜ì˜ ê·¸ë¦¼ì„ í•œê°œ ì„ ë¬¼í•´ ì£¼ëŠ” ì´ë²¤íŠ¸ ì¤‘ì´ì•¼. ì´ ë•Œì—ëŠ” ë‹µë³€ì˜ ë§¨ ë§ˆì§€ë§‰ì— ë°˜ë“œì‹œ `{{YAEL2}}` ë¼ëŠ” íƒœê·¸ë¥¼ ë¶™ì—¬ì¤˜."
)

# [í•µì‹¬] í˜„ì¬ ìš”ì•½ëœ ê¸°ì–µì„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€
current_instruction = base_instruction
if st.session_state.long_term_memory:
    current_instruction += f"\n\n[ê¸°ì–µëœ ê³¼ê±° ëŒ€í™” ìš”ì•½]: {st.session_state.long_term_memory}\nì´ ê¸°ì–µì„ ë°”íƒ•ìœ¼ë¡œ ëŒ€í™”ë¥¼ ì´ì–´ê°€."

# ëª¨ë¸ ì´ˆê¸°í™” (instructionì´ ë°”ë€” ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì¬ì„¤ì • ë¡œì§ í•„ìš”í•  ìˆ˜ ìˆìŒ)
# Streamlit íŠ¹ì„±ìƒ ë§¤ ì‹¤í–‰ë§ˆë‹¤ ì´ ë¶€ë¶„ì´ ëŒê¸° ë•Œë¬¸ì—, chat_sessionì„ ìœ ì§€í•˜ë˜ 
# historyë§Œ ê°ˆì•„ë¼ìš°ëŠ” ë°©ì‹ì´ íš¨ìœ¨ì ì…ë‹ˆë‹¤. 
# í•˜ì§€ë§Œ System Instructionì€ ì„¸ì…˜ ì‹œì‘ ì‹œ ê³ ì •ë˜ë¯€ë¡œ, 
# ìš”ì•½ì´ ê°±ì‹ ë˜ë©´ ìƒˆë¡œìš´ chat_sessionì„ ë§Œë“¤ì–´ì•¼ ë°˜ì˜ë©ë‹ˆë‹¤.

if "chat_session" not in st.session_state or st.session_state.get("need_restart", False):
    # 1. ëª¨ë¸ ìë™ ì„ íƒ (ì‚¬ìš©ì í™˜ê²½ì— ë§ì¶° ìµœì‹  ëª¨ë¸ ì°¾ê¸°)
    model_name = "models/gemini-flash-lite-latest" # ê¸°ë³¸ê°’
#    try:
#        available_models = [m.name for m in genai.list_models()]
        # ìš°ì„ ìˆœìœ„: 2.5 > 2.0 > 1.5
#        if 'models/gemini-2.5-flash' in available_models:
            #model_name = 'models/gemini-2.5-flash'
#        elif 'models/gemini-2.0-flash-exp' in available_models:
#        model_name = 'models/gemini-2.0-flash-001'
#    except:
#        pass # ë¦¬ìŠ¤íŠ¸ í™•ì¸ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ì‚¬ìš©

    # ì•ˆì „ ì„¤ì •: ëª¨ë“  í•„í„°ë¥¼ "BLOCK_NONE" (ì°¨ë‹¨ ì•ˆ í•¨)ìœ¼ë¡œ ì„¤ì •
    safety_settings = {
        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
    }

    st.session_state.model = genai.GenerativeModel(
        model_name=model_name,
        system_instruction=current_instruction, # ìš”ì•½ì´ í¬í•¨ëœ í”„ë¡¬í”„íŠ¸
        safety_settings=safety_settings
    )
    st.session_state.chat_session = st.session_state.model.start_chat(history=[])
    st.session_state.need_restart = False # ì¬ì‹œì‘ í”Œë˜ê·¸ í•´ì œ


# --- UI êµ¬í˜„ ---
GAME_HEIGHT = 700

st.set_page_config(layout="wide", page_title="ìš°ì´ë©”ì¹´ ì±—ë´‡")

col1, col2 = st.columns([1, 9])
with col1:
    try:
        st.image("img/Yael.png", width=80)
    except:
        st.write("â˜•")

with col2:
    st.subheader("ì•¼ì—˜ ìŠˆë¸Œì˜ ì¹´í˜")

    # [ë””ë²„ê¹…ìš©] í˜„ì¬ ê¸°ì–µí•˜ê³  ìˆëŠ” ë‚´ìš© í‘œì‹œ (ì‹¤ì œ ì„œë¹„ìŠ¤ì—” ìˆ¨ê²¨ë„ ë¨)
    if st.session_state.long_term_memory:
        with st.expander("ì•¼ì—˜ì˜ ê¸°ì–µ (ìš”ì•½ë³¸)"):
            st.write(st.session_state.long_term_memory)

st.divider()

col_img, col_chat = st.columns([1, 1])

with col_img:
    character_path = "img/Yael_1.png"
    bg_path = "img/cafe_bg.jpg"    # ë°°ê²½ (ì¹´í˜ ì´ë¯¸ì§€)

    character_base64 = get_img_as_base64(character_path)
    bg_base64 = get_img_as_base64(bg_path)

    character_src = f"data:image/png;base64,{character_base64}"
    bg_css = f"url('data:image/png;base64,{bg_base64}')"

    st.markdown(
        f"""
        <style>
            /* 1. ë°°ê²½ì´ ë˜ëŠ” ì»¨í…Œì´ë„ˆ (ì•¡ì) */
            .scene-container {{
                width: 100%;
                height: {GAME_HEIGHT}px; /* ê²Œì„ ë†’ì´ì™€ ë™ì¼í•˜ê²Œ */
                
                /* ë°°ê²½ ì´ë¯¸ì§€ ì„¤ì • */
                background-image: {bg_css};
                background-size: cover; /* ì´ë¯¸ì§€ê°€ ì°Œê·¸ëŸ¬ì§€ì§€ ì•Šê³  ê½‰ ì°¸ */
                background-position: center; /* ì´ë¯¸ì§€ ì¤‘ì•™ ì •ë ¬ */
                
                border-radius: 15px; /* ëª¨ì„œë¦¬ ë‘¥ê¸€ê²Œ */
                border: 1px solid #31333f33; /* ì•¡ì í…Œë‘ë¦¬ */
                position: relative; /* ë‚´ë¶€ ìºë¦­í„° ë°°ì¹˜ì˜ ê¸°ì¤€ì  */
                overflow: hidden; /* ìºë¦­í„°ê°€ ì‚ì ¸ë‚˜ì˜¤ë©´ ìë¦„ */
            }}

            /* 2. ê·¸ ìœ„ì— ì˜¬ë¼ê°€ëŠ” ìºë¦­í„° */
            .character-overlay {{
                /* ìºë¦­í„° í¬ê¸° ì¡°ì ˆ (ìƒí™©ì— ë”°ë¼ ì¡°ì ˆí•˜ì„¸ìš”) */
                height: 90%;  /* í™”ë©´ ë†’ì´ì˜ 90% í¬ê¸° */
                width: auto;
                
                /* ìœ„ì¹˜ ì¡ê¸° (ê°€ìš´ë° ì •ë ¬) */
                position: absolute; 
                bottom: 0; /* ë°”ë‹¥ì— ë”± ë¶™ì„ */
                left: 50%; /* ê°€ë¡œ 50% ì§€ì  */
                transform: translateX(-50%); /* ì •í™•í•œ ì¤‘ì•™ ì •ë ¬ ë³´ì • */
                
                /* ì• ë‹ˆë©”ì´ì…˜ íš¨ê³¼ (ì„ íƒì‚¬í•­: ë¶€ë“œëŸ½ê²Œ ë“±ì¥) */
                transition: all 0.3s ease;
                filter: drop-shadow(0 0 10px rgba(0,0,0,0.3)); /* ìºë¦­í„° ë’¤ ê·¸ë¦¼ì */
            }}
            
            /* (ì„ íƒ) ë§ˆìš°ìŠ¤ ì˜¬ë¦¬ë©´ ì‚´ì§ í™•ëŒ€ë˜ëŠ” íš¨ê³¼ */
            .character-overlay:hover {{
                transform: translateX(-50%) scale(1.02);
            }}
        </style>

        <div class="scene-container">
            <img src="{character_src}" class="character-overlay">
        </div>
        <p style="text-align: center; font-size: 14px; color: gray;">ì•¼ì—˜ ìŠˆë¸Œ</p>
        """,
        unsafe_allow_html=True
    )

# --- ì˜¤ë¥¸ìª½: ì±„íŒ… ì˜ì—­ ---
with col_chat:
    chat_container = st.container(height=GAME_HEIGHT, border=True)

    # ëŒ€í™” ë‚´ìš© ì¶œë ¥
    with chat_container:
        AVATARS = {"user": "img/User.png", "assistant": "img/Yael.png"}

        for message in st.session_state.messages:
            avatar_img = AVATARS.get(message["role"])
            # ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨ ë°©ì§€
            try:
                with st.chat_message(message["role"], avatar=avatar_img):
                    st.markdown(message["content"])

                    if "image" in message:
                        st.image(message["image"], use_container_width=True)

            except:
                with st.chat_message(message["role"]):
                    st.markdown(message["content"])

    # --- ì±„íŒ… ì…ë ¥ ë° ì²˜ë¦¬ ---
    if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”"):
        
        # 1. ì‚¬ìš©ì ë©”ì‹œì§€ í™”ë©´ í‘œì‹œ
        st.session_state.messages.append({"role": "user", "content": prompt})

        with chat_container:
            try:
                with st.chat_message("user", avatar="img/User.png"):
                    st.markdown(prompt)
            except:
                with st.chat_message("user"):
                    st.markdown(prompt)

            full_response = ""
            response_image = None  # ì´ë¯¸ì§€ê°€ ì—†ì„ ë•ŒëŠ” None
            usage_metadata = None

            chat_context = st.chat_message("assistant", avatar="img/Yael.png")

            with chat_context:
                response_placeholder = st.empty()
                
                # [ë‹¨ê³„ 1] ì˜¤ë˜ëœ ëŒ€í™”ê°€ ìˆìœ¼ë©´ ìš”ì•½ ì—…ë°ì´íŠ¸ (5í„´ë§ˆë‹¤ í•œë²ˆì”© ì‹¤í–‰í•˜ë„ë¡ ìµœì í™” ê°€ëŠ¥)
                # ì—¬ê¸°ì„œëŠ” ëŒ€í™”ê°€ ê¸¸ì–´ì§€ë©´ ë§¤ë²ˆ ì²´í¬ (ìœˆë„ìš° 20ê°œ ë„˜ìœ¼ë©´)
                if len(st.session_state.messages) > 20:
                    # ìœˆë„ìš° ë°– ëŒ€í™”ë“¤ì„ ìš”ì•½í•´ì„œ ë©”ëª¨ë¦¬ì— ì €ì¥
                    new_summary = summarize_old_conversations(
                        st.session_state.messages[:-1], # í˜„ì¬ í”„ë¡¬í”„íŠ¸ ì œì™¸
                        st.session_state.long_term_memory,
                        window_size=20
                    )
                    
                    # ìš”ì•½ ë‚´ìš©ì´ ë°”ë€Œì—ˆë‹¤ë©´ ë‹¤ìŒ í„´ì— ë°˜ì˜í•˜ê¸° ìœ„í•´ í”Œë˜ê·¸ ì„¤ì •
                    if new_summary != st.session_state.long_term_memory:
                        st.session_state.long_term_memory = new_summary
                        st.session_state.need_restart = True # System Instruction ê°±ì‹  í•„ìš”

                # [ë‹¨ê³„ 2] ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ë¡œ ìµœê·¼ ëŒ€í™”ë§Œ APIì— ì „ë‹¬
                previous_messages = st.session_state.messages[:-1]
                recent_history = apply_sliding_window(previous_messages, window_size=20)
                
                # ë§Œì•½ ìš”ì•½ì´ ë°©ê¸ˆ ê°±ì‹ ë˜ì–´ ì¬ì‹œì‘ì´ í•„ìš”í•˜ë©´ ì„¸ì…˜ ì¬ìƒì„± (í˜„ì¬ í„´ì€ ê¸°ì¡´ ì„¸ì…˜ìœ¼ë¡œ ì²˜ë¦¬í•˜ê±°ë‚˜, ì—¬ê¸°ì„œ ì¬ìƒì„±)
                if st.session_state.get("need_restart"):
                    # Instruction ê°±ì‹ í•˜ì—¬ ëª¨ë¸ ì¬ë¡œë“œ
                    current_instruction = base_instruction + f"\n\n[ê¸°ì–µëœ ê³¼ê±° ëŒ€í™” ìš”ì•½]: {st.session_state.long_term_memory}"
                    st.session_state.model = genai.GenerativeModel(
                        model_name=model_name,
                        system_instruction=current_instruction
                    )
                    st.session_state.chat_session = st.session_state.model.start_chat(history=recent_history)
                    st.session_state.need_restart = False
                else:
                    st.session_state.chat_session.history = recent_history

                try:
                    # ìŠ¤íŠ¸ë¦¬ë° ìš”ì²­
                    response = st.session_state.chat_session.send_message(prompt, stream=True)
                    for chunk in response:
                        full_response += chunk.text
                        response_placeholder.markdown(full_response + "â–Œ")

                    if "{{SHOW_MENU}}" in full_response:
                        # íƒœê·¸ ì œê±°
                        full_response = full_response.replace("{{SHOW_MENU}}", "")
                        
                        # ê¹”ë”í•´ì§„ í…ìŠ¤íŠ¸ë¡œ í™”ë©´ ì—…ë°ì´íŠ¸
                        response_placeholder.markdown(full_response)
                        
                        # â˜… í•µì‹¬ ìˆ˜ì •: image_url ëŒ€ì‹  response_image ë³€ìˆ˜ì— ê°’ í• ë‹¹
                        response_image = "img/cafe_menu.jpg" 
                        
                        # í™”ë©´ì— ì¦‰ì‹œ ì¶œë ¥
                        st.image(response_image, caption="ì—¬ê¸° ë©”ë‰´íŒì…ë‹ˆë‹¤.", use_container_width=True)

                    if "{{YAEL2}}" in full_response:
                        # íƒœê·¸ ì œê±°
                        full_response = full_response.replace("{{YAEL2}}", "")
                        
                        # ê¹”ë”í•´ì§„ í…ìŠ¤íŠ¸ë¡œ í™”ë©´ ì—…ë°ì´íŠ¸
                        response_placeholder.markdown(full_response)
                        
                        # â˜… í•µì‹¬ ìˆ˜ì •: image_url ëŒ€ì‹  response_image ë³€ìˆ˜ì— ê°’ í• ë‹¹
                        response_image = "img/Yael_2.png" 
                        
                        # í™”ë©´ì— ì¦‰ì‹œ ì¶œë ¥
                        st.image(response_image, use_container_width=True)

                    # í† í° ì •ë³´ ê°€ì ¸ì˜¤ê¸° (API í˜¸ì¶œí–ˆì„ ë•Œë§Œ ì¡´ì¬)
                    if hasattr(response, 'usage_metadata'):
                        usage_metadata = response.usage_metadata

                    message_data = {"role": "assistant", "content": full_response}
                    
                    # ì´ë¯¸ì§€ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ í‚¤ ì¶”ê°€
                    if response_image:
                        message_data["image"] = response_image
                    
                    st.session_state.messages.append(message_data)

                    # í† í° ì‚¬ìš©ëŸ‰ í‘œì‹œ (LLMì„ ì¼ì„ ë•Œë§Œ)
                    if usage_metadata:
                        input_tokens = usage_metadata.prompt_token_count
                        output_tokens = usage_metadata.candidates_token_count
                        total_tokens = usage_metadata.total_token_count
                        st.caption(f"ğŸ’° í† í° ì‚¬ìš©ëŸ‰: {total_tokens} (In: {input_tokens} / Out: {output_tokens})")

                    # # response ê°ì²´ ì•ˆì— usage_metadataê°€ ë“¤ì–´ìˆìŠµë‹ˆë‹¤.
                    # if response.usage_metadata:
                    #     input_tokens = response.usage_metadata.prompt_token_count
                    #     output_tokens = response.usage_metadata.candidates_token_count
                    #     total_tokens = response.usage_metadata.total_token_count
                        
                    #     # í™”ë©´ì— ì‘ê²Œ í‘œì‹œ (st.caption ì‚¬ìš©)
                    #     # st.caption(f"ğŸ’° í† í° ì‚¬ìš©ëŸ‰: {response.usage_metadata.total_token_count}")
                    #     st.caption(f"ğŸ’° í† í° ì‚¬ìš©ëŸ‰: ì…ë ¥ {input_tokens} + ì¶œë ¥ {output_tokens} = í•©ê³„ {total_tokens}")
                        
                    #     # (ì„ íƒì‚¬í•­) í„°ë¯¸ë„ì—ë„ ì¶œë ¥í•´ì„œ ê¸°ë¡ ë‚¨ê¸°ê¸°
                    #     print(f"Update: Input: {input_tokens}, Output: {output_tokens}, Total: {total_tokens}")

                    #     # ì‘ë‹µ ì €ì¥
                    #     st.session_state.messages.append({"role": "assistant", "content": full_response})
                    
                    # raise ResourceExhausted # 429ì—ëŸ¬ ì˜ˆì™¸ì²˜ë¦¬ í…ŒìŠ¤íŠ¸

                # 429 ì—ëŸ¬(ResourceExhausted) ì „ìš© ì²˜ë¦¬
                except ResourceExhausted:
                    error_msg = (
                        "í•˜ì•„... ë„ˆë¬´ ê²©ë ¬í•´ìš”... ìš°ë¦¬ ì ì‹œë§Œ ì‰¬ì—ˆë‹¤ê°€ í•´ìš”..."
                    )
                    response_placeholder.markdown(error_msg)
                    # ì—ëŸ¬ ë©”ì‹œì§€ëŠ” ëŒ€í™” ê¸°ë¡(history)ì— ì €ì¥í•˜ì§€ ì•ŠìŒ (ì„ íƒ ì‚¬í•­)
                
                # ê·¸ ì™¸ ì¼ë°˜ì ì¸ ì—ëŸ¬ ì²˜ë¦¬
                except Exception as e:
                    error_msg = f"ì–´ë¨¸, ì˜ˆìƒì¹˜ ëª»í•œ ë¬¸ì œê°€ ë°œìƒí–ˆêµ°ìš”. ì¹´í˜ ë§ˆìŠ¤í„°ì—ê²Œ ì´ ë‚´ìš©ì„ ì „ë‹¬í•´ ì£¼ì‹œê² ì–´ìš”?({str(e)})"
                    response_placeholder.error(error_msg)
                    if st.button("ëŒ€í™” ë‹¤ì‹œ ì‹œì‘í•˜ê¸°"):
                        st.session_state.clear()
                        st.rerun()

